##### 安装scrapy

- 修改镜像源

  ```
  pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
  ```

- 安装scrapy

  ```
  pip install scrapy
  ```

- 更新scrapy

  ```
  pip install -U scrapy
  ```



##### 创建项目

- 创建项目目录

  ```
  scrapy startproject scrapy0213
  
  cd scrapy0213
  ```

- 创建蜘蛛程序

  ```
  scrapy genspider 蜘蛛名 爬取网站url
  
  scrapy genspider douban movie.douban.com
  ```

- 查看结构目录

  ```
  pert.@192 scrapy0213 % tree
  .
  ├── scrapy.cfg
  └── scrapy0213
      ├── __init__.py
      ├── __pycache__
      │   ├── __init__.cpython-311.pyc
      │   └── settings.cpython-311.pyc
      ├── items.py
      ├── middlewares.py
      ├── pipelines.py
      ├── settings.py
      └── spiders
          ├── __init__.py
          ├── __pycache__
          │   └── __init__.cpython-311.pyc
          └── douban.py
  
  4 directories, 11 files
  ```



##### 添加项目的虚拟环境解释器

- 点击PyCharm的settings

- 点击Project

- 点击Python 解释器

- 添加新的解释器（放在项目目录里，目录命名为venv）

- 装依赖项

  ```
  打开终端（默认打开是虚拟环境）
  pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
  
  pip install scrapy
  ```

  

##### 编写蜘蛛程序

- 修改起始页面的链接(douban.py)：**start_urls**

  ```
  import scrapy
  #导入Selector
  from scrapy import Selector
  
  class BsrsSpider(scrapy.Spider):
      name = "douban"
      allowed_domains = ["movie.douban.com"]
      start_urls = ["https://movie.douban.com/top250"]
  
      def parse(self, response):
          pass
  ```

- 解析页面（parse函数）

  ```
  from scrapy0213.items import MovieItem
  
  def parse(self, response):
      sel = Selector(response)
      item_lists = sel.xpath('//*[@id="content"]/div/div[1]/ol/li')
      for item_list in item_lists:
          #定义管道处理的对象
          movie_item = MovieItem()
          #extract_first() 获取sel对象第一个内容，并接收到item里
          movie_item['title'] = item_list.xpath('./div/div[2]/div[1]/a/span[1]/text()').extract_first()
          movie_item['rank'] = item_list.xpath('./div/div[2]/div[2]/div/span[2]/text()').extract_first()
          movie_item['subject'] = item_list.xpath('./div/div[2]/div[2]/p[2]/span/text()').extract_first()
          yield movie_item
  ```

- 将数据组装成item对象（数据由哪些字段构成）：**items.py**

  ```
  # Define here the models for your scraped items
  #
  # See documentation in:
  # https://docs.scrapy.org/en/latest/topics/items.html
  
  import scrapy
  
  
  class Scrapy0213Item(scrapy.Item):
      # define the fields for your item here like:
      # name = scrapy.Field()
      pass
  
  #爬虫获取到的数据组装成Item对象
  class MovieItem(scrapy.Item):
      title = scrapy.Field()
      rank = scrapy.Field()
      subject = scrapy.Field()
  ```

- 修改settings.py文件对项目进行配置，主要需要修改以下几个配置

  ```
  #用户浏览器
  USER_AGENT
  
  #并发请求数量 设置为2的多少次方
  CONCURRENT_REQUESTS
  
  #下载延迟
  DOWNLOAD_DELAY = 3
  
  #随机化下载延迟
  RANDOMIZE_DOWNLOAD_DELAY = True
  
  #是否遵循爬虫协议
  ROBOTSTXT_OBEY = True
  
  #配置数据管道
  ITEM_PIPELINES = {
  	'demo.pipelines.MovieItemPipeline':300
  }
  ```

- 运行爬虫

  ```
  scrapy crawl douban -o douban.csv --nolog
  
  #执行douban的蜘蛛程序
  #-o  指定生成文件
  #--nolog 不输出日志
  ```

  

