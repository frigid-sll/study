##### Scrapy概述

Scrapy是基于Python的一个非常流行的网络爬虫框架，可以用来抓取Web站点并从页面中提取结构化的数据。下图展示了Scrapy的基本框架，其中包含了主要组件和系统的数据处理流程。

![image-20230213120822569](/Users/pert./Library/Application Support/typora-user-images/image-20230213120822569.png)

- ITEM PIPELINES：数据管道，负责处理由蜘蛛从网页中抽取的数据条目，它的主要任务是清理、验证和存储数据。当页面被蜘蛛解析后，将被发送到数据管道，并经过几个特定的次序处理数据。每个数据管道组件都是一个Python类，他们获取了数据条目后并执行对数据条目进行处理的方法，同时还需要确定是否需要在数据管道中继续执行下一步或是直接丢弃不处理，数据管道通畅执行的任务有：清理HTML数据、验证解析到的数据、检查是不是重复数据、将解析到的数据存储到数据库
- ENGINE：引擎，用来控制整个系统的数据处理流程
- SPIDERS：蜘蛛程序，用户自定义的用来解析网页并抓取特定的URL的类，每个蜘蛛都能处理一个域名或一组域名，简单的说就是用来自定义特定网站的抓取和解析规则的模块。
- SCHEDULER：调度器，从引擎接受请求并排序列入队列，并在引擎发出请求后返还给他们
- DOWNLOADER：下载器，抓取网页并将网页内容返回给蜘蛛
- Middlewares：中间件是介于引擎和其他组件之间的一个钩子框架，主要是为了提供自定义的代码来拓展Scrapy的功能，包括了下载器中间件和蜘蛛中间件。



##### 流程（不断重复执行，直到请求全部完成）

- 引擎从蜘蛛程序拿到请求
- 引擎将请求交给调度器进行调度，将没有爬取过的请求进行排队，队列方式
- 调度器将要爬取的请求给引擎
- 引擎在将要爬取的请求交给下载器
- 下载器用网络连接进行下载
- 下载后的东西包装成RESPONSE在交给引擎
- 引擎拿到数据后交给蜘蛛程序
- 蜘蛛程序将数据进行处理，组装成ITEM对象
- 蜘蛛程序将ITEM对象交给引擎
- 引擎再将ITEM对象交给管道处理